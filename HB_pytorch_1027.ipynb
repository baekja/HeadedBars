{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32786ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import openpyxl\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "#import tensorflow as tf\n",
    "\n",
    "df = pd.read_excel(\"Data for headed bars_for DataFrame_220725.xlsx\", skiprows = 17, engine = 'openpyxl', sheet_name= 'headed (2)' )\n",
    "df = pd.DataFrame(df, columns = [\"No.\", \"Author\", \"Year\", \"Test type\", \"Remark\", \"Specimen\", \"fy\", \"Ld\", \"fcm\", \"db\", \"b\", \"cos,avg\",\n",
    "                                 \"cth\", \"ch\", \"Nh\", \"Bottom cover\", \"Ah/Ab\", \"Fsu at La, test\", \"dtr\", \"Ntr\", \"st\"]) # st 제거시\n",
    "\n",
    "df = df[df[\"Test type\"] == \"Joint type\"]\n",
    "y= df[\"Fsu at La, test\"] \n",
    "\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "y2=y[~y.isnull()]\n",
    "X = df[[\"Test type\", \"fy\", \"Ld\", \"fcm\", \"db\", \"b\", \"cos,avg\", \"cth\", \"ch\", \"Nh\", \"Bottom cover\", \"Ah/Ab\", \"st\"]] \n",
    "\n",
    "X = pd.get_dummies(data = X, columns = [\"Test type\"], prefix = \"Test_type\")\n",
    "X = X[~y.isnull()]\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "X.dropna(inplace = True)\n",
    "\n",
    "y2 = y2[X.index]\n",
    "y2 = y2.loc[(y2 != 0)] # series\n",
    "X = X.loc[y2.index] # DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71a52b",
   "metadata": {},
   "source": [
    "* train, test 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ec08cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test, train+valid 분류\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.20, random_state=142)\n",
    "#print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0b136",
   "metadata": {},
   "source": [
    "* 분류한 데이터 스케일링 후 텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60f9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류한 데이터 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scX = MinMaxScaler() #형태는 넘파이\n",
    "x_train_scaled = scX.fit_transform(X_train)   \n",
    "x_test_scaled = scX.transform(X_test)\n",
    "\n",
    "scY = MinMaxScaler()\n",
    "y_train_scaled = scY.fit_transform(y_train.values.reshape(-1,1)) \n",
    "y_test_scaled = scY.transform(y_test.values.reshape(-1,1))\n",
    "\n",
    "#스케일링->텐서로\n",
    "x_test_tensor = torch.FloatTensor(x_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test_scaled)\n",
    "x_train_tensor = torch.FloatTensor(x_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38f51c",
   "metadata": {},
   "source": [
    "* 파이토치 이용한 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbf063d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size : 172\n",
      "Validation Data Size : 44\n"
     ]
    }
   ],
   "source": [
    "#데이터 모델 클래스로 구현\n",
    "class  MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super( MyModel, self).__init__()\n",
    "        self.layer = nn.Linear(13, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "#커스텀 데이터 셋\n",
    "class CustomDataset(TensorDataset): \n",
    "    def __init__(self):\n",
    "        self.x = x_train_tensor\n",
    "        self.y = y_train_tensor\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x[idx])\n",
    "        y = torch.FloatTensor(self.y[idx]) \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.x)\n",
    "\n",
    "#데이터 셋에서 train, validation 나누기 \n",
    "dataset = CustomDataset()\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "validation_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
    "\n",
    "# 데이터 로더\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab14e26",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e66eac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kds/VSProjects/HeadedBars_231030/HeadedBars/HB_pytorch_1027.ipynb 셀 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.180.186.161/home/kds/VSProjects/HeadedBars_231030/HeadedBars/HB_pytorch_1027.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         cost \u001b[39m=\u001b[39m criterion(prediction, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.180.186.161/home/kds/VSProjects/HeadedBars_231030/HeadedBars/HB_pytorch_1027.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m         val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cost\u001b[39m.\u001b[39mitem()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.180.186.161/home/kds/VSProjects/HeadedBars_231030/HeadedBars/HB_pytorch_1027.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m         val_accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(prediction \u001b[39m==\u001b[39m y\u001b[39m.\u001b[39mdata)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m/\u001b[39mx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m#분류에 사용\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.180.186.161/home/kds/VSProjects/HeadedBars_231030/HeadedBars/HB_pytorch_1027.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# calculate mean for each batch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.180.186.161/home/kds/VSProjects/HeadedBars_231030/HeadedBars/HB_pytorch_1027.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MyModel().to(device)\n",
    "criterion = nn.MSELoss().to(device) #\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.03) #\n",
    "nb_epochs = 10000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    train_loss = 0       \n",
    "    train_accuracy = 0 \n",
    "    for _,data in enumerate(train_dataloader):\n",
    "        x,y =data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        prediction = model(x)\n",
    "        cost =criterion(prediction, y)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += cost.item()\n",
    "        #train_accuracy += torch.sum(prediction == y.data).detach().cpu().numpy()/x.size(0)\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    #val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for _,data in enumerate(validation_dataloader):\n",
    "            x,y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            prediction = model(x)\n",
    "            cost = criterion(prediction, y)\n",
    "            \n",
    "            val_loss += cost.item()\n",
    "            #val_accuracy += torch.sum(prediction == y.data).detach().cpu().numpy()/x.size(0) #분류에 사용\n",
    "\n",
    "    # calculate mean for each batch\n",
    "    train_losses.append(train_loss / len(train_dataloader))\n",
    "    val_losses.append(val_loss / len(validation_dataloader))\n",
    "    train_acc.append(train_accuracy / len(train_dataloader))\n",
    "    val_acc.append(val_accuracy / len(validation_dataloader))\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(\"Epoch:{:4d}/{}\".format(epoch, nb_epochs),\n",
    "              \"Train Loss: {:.6f}\".format(train_loss / len(train_dataloader)),\n",
    "              \"Val Loss: {:.6f}\".format(val_loss / len(validation_dataloader)))\n",
    "              \n",
    "\n",
    "history = {'train_loss': train_losses, 'val_loss': val_losses,\n",
    "            'train_acc': train_acc, 'val_acc': val_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64041653",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(history['train_loss'],label = \"Train loss\")\n",
    "plt.plot(history['val_loss'],label = \"Valid loss\")\n",
    "plt.title(f'Loss', color='white', fontweight = 'bold')\n",
    "plt.ylabel('Loss', color='white')\n",
    "plt.xlabel('epoch', color='white')\n",
    "\n",
    "plt.legend(), plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea241b",
   "metadata": {},
   "source": [
    "평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12191ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "y_p = model(x_test_tensor)\n",
    "y_p[:10], y_test_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32103b63",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "y_test_unscaled = scY.inverse_transform(y_test_scaled)  \n",
    "print(len(y_test_unscaled),y_test_unscaled, type(y_test_unscaled))\n",
    "\n",
    "y_p_unscaled = scY.inverse_transform(y_p.detach().numpy())\n",
    "print(len(y_p_unscaled),y_p_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7446dfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.plot(y_test_unscaled, y_p_unscaled, 'r.')\n",
    "ax.set_xlabel(\"Tested tensile stress, ft_test (MPa)\", fontsize = 14,color = 'white')\n",
    "ax.set_ylabel(\"Predicted tensile stress, ft_pred (MPa)\", fontsize = 14, color = 'white')\n",
    "x = np.linspace(0, 1000, 100)\n",
    "y = x\n",
    "ax.plot(x, y, 'b')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18f5a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "x_test_unscaled = scX.inverse_transform(x_test_scaled)  \n",
    "print(x_test_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d612d262",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73594a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "#test_accuracy = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(y_test_unscaled)):\n",
    "        pred = model(x_test_tensor)\n",
    "        cost = criterion(pred, y_test_tensor)\n",
    "        test_loss += cost.item()\n",
    "        #test_accuracy += torch.sum(pred == y_test_tensor).detach().cpu().numpy()/x_test_tensor.size(0)\n",
    "        \n",
    "    print('test_loss:',test_loss)\n",
    "    #print(f'test_acc:{test_accuracy:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151588b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "division = y_p_unscaled / y_test_unscaled\n",
    "cov = np.std(division) / np.mean(division)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc500906",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test_unscaled, y_p_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d191d63",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856fb5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'HeadedBars'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n HeadedBars ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
